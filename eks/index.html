
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../storage/">
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.4.0">
    
    
      
        <title>AWS EKS - AWS Documentation</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.9f615399.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.649f08f9.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="light-blue">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#amazon-elastic-kubernetes-service-eks" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="AWS Documentation" class="md-header__button md-logo" aria-label="AWS Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            AWS Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              AWS EKS
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="AWS Documentation" class="md-nav__button md-logo" aria-label="AWS Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    AWS Documentation
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AWS
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../ec2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AWS Compute
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../elb/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AWS Load Balancers
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../storage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AWS Storage
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    AWS EKS
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    AWS EKS
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#amazon-elastic-kubernetes-service-eks" class="md-nav__link">
    Amazon Elastic Kubernetes Service (EKS)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#installation-and-setup-steps" class="md-nav__link">
    Installation and Setup Steps
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deploying-a-cloud-native-application" class="md-nav__link">
    Deploying a Cloud Native Application
  </a>
  
    <nav class="md-nav" aria-label="Deploying a Cloud Native Application">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#deployment-steps" class="md-nav__link">
    Deployment Steps
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mongodb-deployment" class="md-nav__link">
    MongoDB Deployment
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#api-backend-deployment" class="md-nav__link">
    API (Backend) Deployment
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#frontend-deployment" class="md-nav__link">
    Frontend Deployment
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#associating-iam-roles-with-kubernetes-service-accounts-in-amazon-eks" class="md-nav__link">
    Associating IAM Roles with Kubernetes Service Accounts in Amazon EKS
  </a>
  
    <nav class="md-nav" aria-label="Associating IAM Roles with Kubernetes Service Accounts in Amazon EKS">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#setting-up-iam-roles" class="md-nav__link">
    Setting up IAM Roles
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#aws-load-balancer-controller-and-ingress-resource" class="md-nav__link">
    AWS Load Balancer Controller and Ingress Resource
  </a>
  
    <nav class="md-nav" aria-label="AWS Load Balancer Controller and Ingress Resource">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#deploy-aws-load-balancer-controller" class="md-nav__link">
    Deploy AWS Load Balancer Controller
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deploy-and-expose-the-web-app" class="md-nav__link">
    Deploy and Expose the Web App
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#amazon-elastic-kubernetes-service-eks" class="md-nav__link">
    Amazon Elastic Kubernetes Service (EKS)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#installation-and-setup-steps" class="md-nav__link">
    Installation and Setup Steps
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deploying-a-cloud-native-application" class="md-nav__link">
    Deploying a Cloud Native Application
  </a>
  
    <nav class="md-nav" aria-label="Deploying a Cloud Native Application">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#deployment-steps" class="md-nav__link">
    Deployment Steps
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mongodb-deployment" class="md-nav__link">
    MongoDB Deployment
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#api-backend-deployment" class="md-nav__link">
    API (Backend) Deployment
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#frontend-deployment" class="md-nav__link">
    Frontend Deployment
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#associating-iam-roles-with-kubernetes-service-accounts-in-amazon-eks" class="md-nav__link">
    Associating IAM Roles with Kubernetes Service Accounts in Amazon EKS
  </a>
  
    <nav class="md-nav" aria-label="Associating IAM Roles with Kubernetes Service Accounts in Amazon EKS">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#setting-up-iam-roles" class="md-nav__link">
    Setting up IAM Roles
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#aws-load-balancer-controller-and-ingress-resource" class="md-nav__link">
    AWS Load Balancer Controller and Ingress Resource
  </a>
  
    <nav class="md-nav" aria-label="AWS Load Balancer Controller and Ingress Resource">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#deploy-aws-load-balancer-controller" class="md-nav__link">
    Deploy AWS Load Balancer Controller
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deploy-and-expose-the-web-app" class="md-nav__link">
    Deploy and Expose the Web App
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  <h1>AWS EKS</h1>

<h2 id="amazon-elastic-kubernetes-service-eks">Amazon Elastic Kubernetes Service (EKS)</h2>
<p>Amazon Elastic Kubernetes Service (Amazon EKS) is a fully managed Kubernetes service that enables you to run Kubernetes seamlessly in both AWS Cloud and on-premises data centers.</p>
<p>First you need to get into the AWS platform and then search EC2 and create a Cluster and Node Group. You can then interact with your EKS cluster by SSH-ing into your EKS cluster. Alternatively, you can also set up an EC2 instance to interact with your EKS cluster.</p>
<p>In preparation to manage your EKS Kubernetes cluster, you will need to install several Kubernetes management-related tools and utilities. In this lab step, you will install:</p>
<ul>
<li><strong>kubectl:</strong> the Kubernetes command-line utility which is used for communicating with the Kubernetes Cluster API server</li>
<li><strong>awscli:</strong> used to query and retrieve your Amazon EKS cluster connection details, written into the <code>~/.kube/config</code> file </li>
</ul>
<h2 id="installation-and-setup-steps">Installation and Setup Steps</h2>
<ul>
<li>Download the <code>kubectl</code> utility, give it executable permissions, and copy it into a directory that is part of the PATH environment variable:</li>
</ul>
<pre><code class="language-bash">curl -O https://s3.us-west-2.amazonaws.com/amazon-eks/1.31.0/2024-09-12/bin/linux/amd64/kubectl
chmod +x ./kubectl
sudo cp ./kubectl /usr/local/bin
export PATH=/usr/local/bin:$PATH
</code></pre>
<ul>
<li>Test the kubectl utility, ensuring that it can be called like so:</li>
</ul>
<pre><code class="language-bash">kubectl version --client=true
</code></pre>
<ul>
<li>Download the AWS CLI utility, give it executable permissions, and copy it into a directory that is part of the PATH environment variable:</li>
</ul>
<pre><code class="language-bash">curl &quot;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip&quot; -o &quot;awscliv2.zip&quot;
unzip awscliv2.zip
sudo ./aws/install
</code></pre>
<ul>
<li>Test the <code>aws</code> utility -</li>
</ul>
<pre><code class="language-bash">aws --version
</code></pre>
<ul>
<li>Use the <code>aws</code> utility, to retrieve EKS Cluster name:</li>
</ul>
<pre><code class="language-bash">EKS_CLUSTER_NAME=$(aws eks list-clusters --region us-west-2 --query clusters[0] --output text)
echo $EKS_CLUSTER_NAME
</code></pre>
<ul>
<li>Use the <code>aws</code> utility to query and retrieve your Amazon EKS cluster connection details, saving them into the ~/.kube/config file. Enter the following command in the terminal:</li>
</ul>
<pre><code class="language-bash">aws eks update-kubeconfig --name $EKS_CLUSTER_NAME --region us-west-2 
</code></pre>
<ul>
<li>View the EKS Cluster connection details. This confirms that the EKS authentication credentials required to authenticate have been correctly copied into the ~/.kube/config file. Enter the following command in the terminal:</li>
</ul>
<pre><code class="language-bash">cat ~/.kube/config 
</code></pre>
<h2 id="deploying-a-cloud-native-application">Deploying a Cloud Native Application</h2>
<p>The cloud native application has three parts - Frontend, Backend and Database. Both the Frontend and Backend has particular Service and Deployment manifest for them. The Database has StatefulSet, Service, Persistent Volume (PV) and Persistent Volume Claim (PVC).</p>
<ul>
<li>StatefulSet - used to deploy and launch 3 x pods containing the MongoDB service configured to listen on port 27017</li>
<li>Service - headless, will be created to sit in front of the StatefulSet, creating a stable network name for each of the individual pods as well as for the StatefulSet as a whole</li>
<li>Persistent Volume (PV) - x3, 1 for each individual pod in the StatefulSet - MongoDB will be configured to persist all data and configuration into a directory mounted to the persistent volume</li>
<li>Persistent Volume Claim (PVC) - x3, 1 for each PV, binds a PV to a Pod within the MongoDB StatefulSet</li>
</ul>
<h4 id="deployment-steps">Deployment Steps</h4>
<ul>
<li>Begin by creating a namespace,  which will be used to contain all of the cluster resources that will eventually make up the sample cloud native application. In the terminal run the following command:</li>
</ul>
<pre><code class="language-bash">cat &lt;&lt; EOF | kubectl apply -f -
apiVersion: v1
kind: Namespace
metadata:
  name: cloudacademy
  labels:
    name: cloudacademy
EOF
</code></pre>
<ul>
<li>Configure the <code>cloudacademy</code> namespace to be the default. In the terminal run the following command:</li>
</ul>
<pre><code class="language-bash">kubectl config set-context --current --namespace cloudacademy
</code></pre>
<h4 id="mongodb-deployment">MongoDB Deployment</h4>
<ul>
<li>Deploy the MongoDB 3 x ReplicaSet</li>
<li>Display the available EKS storage classes. In the terminal run the following command:</li>
</ul>
<pre><code class="language-bash">kubectl get storageclass
</code></pre>
<ul>
<li>Create a new Mongo StatefulSet name <code>mongo</code>. Also keep in mind to use the <code>storageclass</code> we got before in the <code>storageClassName</code>. <ul>
<li>Examine the MongoDB Pods ordered sequence launch. Run a <code>watch</code> on the pods in the current namespace. Wait until all 3 MongoDB pods (<code>mongo-0</code>, <code>mongo-1</code>, <code>mongo-2</code>) have reached and recorded the Running status. <code>kubectl get pods --watch</code></li>
<li>View the pods with the db label in the current namespace. In the terminal run the following command: <code>kubectl get pods -l role=db</code></li>
<li>Display the MongoDB Pods, Persistent Volumes and Persistent Volume Claims. <code>kubectl get pod,pv,pvc</code></li>
</ul>
</li>
<li>Create a new Headless Service for Mongo. Examine the newly created <code>mongo</code> Headless Service. <code>kubectl get svc</code></li>
<li>Create a temporary network utils pod. Enter into a bash session within it. <code>kubectl run --rm utils -it --image praqma/network-multitool -- bash</code>. Creating a temporary utils pod in the current namespace - ensures that the <code>nslookup</code> queries to be performed next, are done so in the same networking space in which the MongoDB deployment has taken place in.<ul>
<li>Within the new utils pod shell, execute the following DNS queries: <code>for i in {0..2}; do nslookup mongo-$i.mongo; done</code>. This confirms that the DNS records have been created successfully and can be resolved within the cluster, 1 per MongoDB pod that exists behind the Headless Service - earlier created. Exit the utils container: <code>exit</code></li>
</ul>
</li>
<li>Confirm that the <code>mongo</code> shell can now also resolve each of the 3 Mongo headless Service assigned DNS names. In the terminal run the following command:</li>
</ul>
<pre><code class="language-bash">for i in {0..2}; do kubectl exec -it mongo-0 -- mongo mongo-$i.mongo --eval &quot;print('mongo-$i.mongo SUCCEEDED\n')&quot;; done
</code></pre>
<ul>
<li>Before proceeding to the next step, make sure that the previous command has completed successfully as per the output shown in the screenshot above. </li>
<li>On the mongo-0 pod, initialise the Mongo database Replica set. In the terminal run the following command:</li>
</ul>
<pre><code class="language-bash">cat &lt;&lt; EOF | kubectl exec -it mongo-0 -- mongo
rs.initiate();
sleep(2000);
rs.add(&quot;mongo-1.mongo:27017&quot;);
sleep(2000);
rs.add(&quot;mongo-2.mongo:27017&quot;);
sleep(2000);
cfg = rs.conf();
cfg.members[0].host = &quot;mongo-0.mongo:27017&quot;;
rs.reconfig(cfg, {force: true});
sleep(5000);
EOF
</code></pre>
<ul>
<li>Confirm that the MongoDB database replica set has been correctly established. In the terminal run the following command:</li>
</ul>
<pre><code class="language-bash">kubectl exec -it mongo-0 -- mongo --eval &quot;rs.status()&quot; | grep &quot;PRIMARY\|SECONDARY&quot;
</code></pre>
<ul>
<li>Load the initial voting app data into the MongoDB database.</li>
<li>Confirm the voting app data has been loaded correctly. In the terminal run the following command:</li>
</ul>
<pre><code class="language-bash">kubectl exec -it mongo-0 -- mongo langdb --eval &quot;db.languages.find().pretty()&quot;
</code></pre>
<h4 id="api-backend-deployment">API (Backend) Deployment</h4>
<ul>
<li>Create a secret to store the MongoDB connection credentials</li>
<li>Generate username and password credentials:</li>
</ul>
<pre><code class="language-bash">echo -n 'admin' | base64
echo -n 'password' | base64
</code></pre>
<ul>
<li>Create a Secret resource within the cluster to hold the base64 encoded credentials.</li>
</ul>
<pre><code class="language-bash">cat &lt;&lt; EOF | kubectl apply -f -
apiVersion: v1
kind: Secret
metadata:
  name: mongodb-secret
  namespace: cloudacademy
data:
  username: YWRtaW4=
  password: cGFzc3dvcmQ=
EOF
</code></pre>
<ul>
<li>Create the API Deployment resource. </li>
<li>Create a new Service resource of LoadBalancer type</li>
</ul>
<pre><code class="language-bash">kubectl expose deploy api \
 --name=api \
 --type=LoadBalancer \
 --port=80 \
 --target-port=8080
</code></pre>
<ul>
<li>Confirm the API setup within the cluster:<ul>
<li>Examine the rollout of the API deployment</li>
<li>Examine the pods to confirm that they are up and running</li>
<li>Examine the API service details</li>
</ul>
</li>
</ul>
<pre><code class="language-bash">{
kubectl rollout status deployment api
kubectl get pods -l role=api
kubectl get svc api
}
</code></pre>
<ul>
<li>Test and confirm that the API route URL <code>/ok</code> endpoint can be called successfully. In the terminal run the command given below. DNS propagation can take up to 2-5 minutes, please be patient while the propagation proceeds - it will eventually complete.</li>
</ul>
<pre><code class="language-bash">{
API_ELB_PUBLIC_FQDN=$(kubectl get svc api -ojsonpath=&quot;{.status.loadBalancer.ingress[0].hostname}&quot;)
until nslookup $API_ELB_PUBLIC_FQDN &gt;/dev/null 2&gt;&amp;1; do sleep 2 &amp;&amp; echo waiting for DNS to propagate...; done
curl $API_ELB_PUBLIC_FQDN/ok
echo
}
</code></pre>
<ul>
<li>Test and confirm that the API route URL /languages, and /languages/{name} endpoints can be called successfully. In the terminal run any of the following commands:</li>
</ul>
<pre><code class="language-bash">curl -s $API_ELB_PUBLIC_FQDN/languages | jq .
curl -s $API_ELB_PUBLIC_FQDN/languages/go | jq .
curl -s $API_ELB_PUBLIC_FQDN/languages/java | jq .
curl -s $API_ELB_PUBLIC_FQDN/languages/nodejs | jq .
</code></pre>
<h4 id="frontend-deployment">Frontend Deployment</h4>
<p>The frontend deployment steps are same as the backend deployment steps - </p>
<ul>
<li>Retrieve the FQDN of the API LoadBalancer and store it in the <code>$API_PUBLIC_FQDN</code> variable. The value stored in the <code>$API_PUBLIC_FQDN</code> variable is injected into the Frontend container's <code>REACT_APP_APIHOSTPORT</code> environment var - this tells the frontend where to send browser initiated API AJAX calls. In the terminal run the following command:</li>
</ul>
<pre><code class="language-bash">{
API_ELB_PUBLIC_FQDN=$(kubectl get svc api -ojsonpath=&quot;{.status.loadBalancer.ingress[0].hostname}&quot;)
echo API_ELB_PUBLIC_FQDN=$API_ELB_PUBLIC_FQDN
}
</code></pre>
<ul>
<li>Create the Frontend Deployment resource</li>
<li>Create a new Service resource of LoadBalancer type</li>
<li>Confirm the Frontend setup within the cluster:<ul>
<li>Examine the rollout of the Frontend deployment</li>
<li>Examine the pods to confirm that they are up and running</li>
<li>Examine the Frontend service details</li>
</ul>
</li>
</ul>
<pre><code class="language-bash">{
kubectl rollout status deployment frontend
kubectl get pods -l role=frontend
kubectl get svc frontend
}
</code></pre>
<ul>
<li>Confirm that the Frontend ELB is ready to recieve HTTP traffic. In the terminal run the following command:</li>
</ul>
<pre><code class="language-bash">{
FRONTEND_ELB_PUBLIC_FQDN=$(kubectl get svc frontend -ojsonpath=&quot;{.status.loadBalancer.ingress[0].hostname}&quot;)
until nslookup $FRONTEND_ELB_PUBLIC_FQDN &gt;/dev/null 2&gt;&amp;1; do sleep 2 &amp;&amp; echo waiting for DNS to propagate...; done
curl -I $FRONTEND_ELB_PUBLIC_FQDN
}
</code></pre>
<ul>
<li>Generate the Frontend URL for browsing. In the terminal run the following command:</li>
</ul>
<pre><code class="language-bash">echo http://$FRONTEND_ELB_PUBLIC_FQDN
</code></pre>
<ul>
<li>Query the MongoDB database directly to observe the updated vote data. In the terminal execute the following command:</li>
</ul>
<pre><code class="language-bash">kubectl exec -it mongo-0 -- mongo langdb --eval &quot;db.languages.find().pretty()&quot;
</code></pre>
<h2 id="associating-iam-roles-with-kubernetes-service-accounts-in-amazon-eks">Associating IAM Roles with Kubernetes Service Accounts in Amazon EKS</h2>
<p>In Kubernetes, a Service Account resource provides an identity for processes that run in a Pod. </p>
<p>In Amazon Web Services, an Identity and Access Management (IAM) role performs a similar function. IAM roles provide an identity that permissions can be attached to.</p>
<p>Amazon Elastic Kubernetes Service (EKS) allows you to associate a Kubernetes Service Account with an AWS IAM role. Doing this has the following best-practice security benefits:</p>
<ul>
<li>You can ensure that a Pod only has access to the AWS resources that it requires, adhering to the Principle of Least Privilege</li>
<li>Ensuring that a Pod's AWS IAM credentials are separate from other AWS IAM roles, achieving isolation of credentials</li>
<li>When using IAM and Service Accounts together, you can use <strong>Amazon CloudTrail</strong> to audit credential access</li>
</ul>
<p>Using IAM roles with Kubernetes Service Accounts requires an Open ID Connect (OIDC). EKS can be configured to have a public OIDC discovery endpoint hosted by Amazon for a specific EKS cluster. Using this EKS cluster-specific OIDC provider enables external systems, such as AWS IAM, to accept and verify Kubernetes Service Account tokens. Once an EKS cluster has OIDC configured, it can make use of any of the features of AWS IAM.</p>
<p>Now we want to show a demonstration, where you will deploy an application that accesses Amazon S3, you will create a new Service Account and associate it with an existing IAM role, and you will verify that the application can access Amazon S3.</p>
<h4 id="setting-up-iam-roles">Setting up IAM Roles</h4>
<ul>
<li>Ensure that you have an up to date <code>kubeconfig</code> file</li>
</ul>
<pre><code class="language-bash">cd ~
aws eks --region us-west-2 update-kubeconfig --name Cluster-1
</code></pre>
<ul>
<li>You can create a seperate namespace and set context for that namespace.</li>
</ul>
<pre><code class="language-bash">kubectl create namespace iam-oidc
kubectl config set-context $(kubectl config current-context) --namespace=iam-oidc
</code></pre>
<ul>
<li>To view an IAM role that has Amazon S3 access, enter the following:</li>
</ul>
<pre><code class="language-bash">aws iam get-role --role-name s3-poller-role
</code></pre>
<p>In this case, we will have JSON response showing the <code>AssumeRolePolicyDocument</code>. This allows use of the <code>sts:AssumeRoleWithWebIdentity</code> action by default. The <code>principal</code> for this statement is <code>Federated</code> which allows the use of AWS OIDC Provider as an Amazon Resource Name (ARN). The value of the <code>StringEquals</code> key has a value containing a subset of the <code>Principal</code>'s ARN. This is the identifier for the cluster's OIDC endpoint.</p>
<ul>
<li>To see the policy attached to the <code>s3-poller-role</code>, enter the following:</li>
</ul>
<pre><code class="language-bash">aws iam get-role-policy --role-name s3-poller-role --policy-name s3-poller-policy
</code></pre>
<p>This policy allows the <code>s3:List*</code> and <code>s3:PutObject</code> IAM actions. You will associate this pre-created S3 role with a Kubernetes Service Account.</p>
<ul>
<li>To see this EKS cluster's OIDC endpoint, issue the following in the terminal:</li>
</ul>
<pre><code class="language-bash">aws eks describe-cluster --name Cluster-1 --region us-west-2 --query cluster.identity
</code></pre>
<p>In our case, OIDC is already configured. To turn it on for an EKS cluster that doesn't have you can use the eksctl tool in the following way:</p>
<pre><code class="language-bash">eksctl utils associate-iam-oidc-provider --cluster=&lt;clusterName&gt;
</code></pre>
<ul>
<li>To store the bucket in Amazon S3 in a shell variable, issue the following:</li>
</ul>
<pre><code class="language-bash">BUCKET_NAME=$(aws s3api list-buckets --query &quot;Buckets[0].Name&quot; --output text)
</code></pre>
<ul>
<li>Create a new deployment manifest and apply it.</li>
<li>To update the bucket name in the manifest, use the <code>sed</code> command.</li>
<li>To check that a Pod has been created by the Deployment, enter: <code>kubectl get pod</code> or you can watch it using <code>kubectl get pod -w</code></li>
<li>To view Pod's logs - </li>
</ul>
<pre><code class="language-bash">kubectl logs -l app=s3-poller -f
</code></pre>
<p>The logs of all Pods that have an app label with a value of s3-poller will be displayed. The -f flag is short for follow and it means that kubectl will wait for new log entries and print them as they happen.</p>
<p>The logs of all Pods that have an app label with a value of s3-poller will be displayed. The container running inside the Pod does not have credentials to access AWS resources. You will configure a Service Account for the Pod that is linked to an IAM role so that the container can access Amazon S3.</p>
<ul>
<li>To stop following the logs, press Ctrl-C.</li>
<li>To list currently existing Service Accounts, issue the following:</li>
</ul>
<pre><code class="language-bash">kubectl get serviceaccount
</code></pre>
<p>You will see one Service Account named <code>default</code> listed. A default Service Account is automatically created when a new namespace is created. If no Service Account is specified for a Pod, it will use the namespace's default Service Account.</p>
<p>Service Accounts have tokens. These are stored in Kubernetes Secret resources. Feel free to issue <code>kubectl get secret</code> to see it listed. Also, feel free to add <code>-o yaml</code> to this command and the instruction's command to see the YAML manifest for these resources.</p>
<ul>
<li>To create a new Service Account, enter the following: </li>
</ul>
<pre><code class="language-bash">kubectl create serviceaccount s3-poller
</code></pre>
<ul>
<li>To associate the newly created Service Account with an IAM role, enter the following:</li>
</ul>
<pre><code class="language-bash">kubectl annotate serviceaccount s3-poller \
    'eks.amazonaws.com/role-arn'='arn:aws:iam::708048379844:role/s3-poller-role'
</code></pre>
<ul>
<li>You can verify the Service Account's configuration by issuing:</li>
</ul>
<pre><code class="language-bash">kubectl describe serviceaccount s3-poller
</code></pre>
<ul>
<li>To modify the Deployment to use your new Service Account, issue the following command:</li>
</ul>
<pre><code class="language-bash">kubectl patch deployment s3-poller \
  -p '{&quot;spec&quot;:{&quot;template&quot;:{&quot;spec&quot;:{&quot;serviceAccountName&quot;:&quot;s3-poller&quot;}}}}'
</code></pre>
<ul>
<li>To verify that <code>s3-poller</code> Pod can now access Amazon S3, re-issue the logs command from earlier:</li>
</ul>
<pre><code class="language-bash">kubectl logs -l app=s3-poller
</code></pre>
<h2 id="aws-load-balancer-controller-and-ingress-resource">AWS Load Balancer Controller and Ingress Resource</h2>
<ul>
<li>Before creating the Load Balancer Controller, you need to perform some EKS cluster configuration. The EKS cluster can either be created using GUI or in this case, we will be using <code>eksctl</code> utility. It can be created with the following setting:</li>
</ul>
<pre><code class="language-bash">eksctl create cluster \
--version=1.31 \
--name=Cluster-1 \
--nodes=1 \
--node-type=t2.medium \
--ssh-public-key=&quot;cloudacademylab&quot; \
--region=us-west-2 \
--zones=us-west-2a,us-west-2b,us-west-2c \
--node-volume-type=gp2 \
--node-volume-size=20
</code></pre>
<ul>
<li>An OpenID Connect provider needs to be established. This was performed using the following command:</li>
</ul>
<pre><code class="language-bash">eksctl utils associate-iam-oidc-provider \
--region us-west-2 \
--cluster Cluster-1 \
--approve
</code></pre>
<ul>
<li>A new IAM Policy was created, providing various permissions required to provision the underlying infrastructure items (ALBs and/or NLBs) created when Ingress and Service cluster resources are created.</li>
</ul>
<pre><code class="language-bash">curl -o /tmp/iam_policy.json https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/main/docs/install/iam_policy.json
aws iam create-policy \
--policy-name AWSLoadBalancerControllerIAMPolicy \
--policy-document file:///tmp/iam_policy.json
</code></pre>
<ul>
<li>A new cluster service account bound to the IAM policy has been created. When the AWS Load Balancer controller is later deployed by you, it will be configured to operate with this service account:</li>
</ul>
<pre><code class="language-bash">eksctl create iamserviceaccount \
--cluster Cluster-1 \
--namespace kube-system \
--name aws-load-balancer-controller \
--attach-policy-arn arn:aws:iam::${AWS::AccountId}:policy/AWSLoadBalancerControllerIAMPolicy \
--override-existing-serviceaccounts \
--approve
</code></pre>
<h4 id="deploy-aws-load-balancer-controller">Deploy AWS Load Balancer Controller</h4>
<ul>
<li>Install the <strong>helm</strong> utility. Helm will be used to install the AWS Load Balancer Controller chart. In the terminal run the following commands:</li>
</ul>
<pre><code class="language-bash">{
pushd /tmp
curl -o helm-v3.12.1-linux-amd64.tar.gz https://get.helm.sh/helm-v3.9.2-linux-amd64.tar.gz
tar -xvf helm-v3.12.1-linux-amd64.tar.gz
sudo mv linux-amd64/helm /usr/local/bin/helm
popd
which helm
}
</code></pre>
<ul>
<li>Update the local Helm repo</li>
</ul>
<pre><code class="language-bash">{
helm repo add eks https://aws.github.io/eks-charts
helm repo update
}
</code></pre>
<ul>
<li>Confirm that a cluster service account exists for the AWS Load Balancer Controller. In the terminal run the following command:</li>
</ul>
<pre><code class="language-bash">kubectl get sa aws-load-balancer-controller -n kube-system -o yaml
</code></pre>
<ul>
<li>Retrieve the VPC ID for the VPC that the EKS cluster worker node is deployed within</li>
</ul>
<pre><code class="language-bash">{
VPC_ID=$(aws eks describe-cluster \
--name Cluster-1 \
--query &quot;cluster.resourcesVpcConfig.vpcId&quot; \
--output text)
echo $VPC_ID
}
</code></pre>
<ul>
<li>Deploy the Custom Resource Definition (CRD) resources required by the AWS Load Balancer Controller. In the terminal run the following command:</li>
</ul>
<pre><code class="language-bash">kubectl apply -k &quot;github.com/aws/eks-charts/stable/aws-load-balancer-controller/crds?ref=master&quot;
</code></pre>
<ul>
<li>Using the helm command, deploy the AWS Load Balancer Controller chart. In the terminal run the following command:</li>
</ul>
<pre><code class="language-bash">helm install \
aws-load-balancer-controller \
eks/aws-load-balancer-controller \
-n kube-system \
--set clusterName=Cluster-1 \
--set serviceAccount.create=false \
--set serviceAccount.name=aws-load-balancer-controller \
--set image.tag=v2.5.2 \
--set region=us-west-2 \
--set vpcId=${VPC_ID} \
--version=1.5.3
</code></pre>
<ul>
<li>Confirm that the AWS Load Balancer Controller has been successfully deployed into the cluster. In the terminal run the following command:</li>
</ul>
<pre><code class="language-bash">kubectl -n kube-system rollout status deployment aws-load-balancer-controller
</code></pre>
<ul>
<li>Examine details of the deployed AWS Load Balancer Controller. In the terminal run the following command:</li>
</ul>
<pre><code class="language-bash">kubectl describe deployment -n kube-system aws-load-balancer-controller
</code></pre>
<h4 id="deploy-and-expose-the-web-app">Deploy and Expose the Web App</h4>
<p>In this lab step, you will deploy and set up a sample web app that when requested simply returns a static message on a coloured background. Both the message and the background colour are parameterized, with their configurations specified using ConfigMap resources, mounted to within the pod at launch time. You will launch 2 versions of the same web app, considered V1 (yellow) and V2 (cyan), each with it's own unique message and background colour. Finally, both versions of the web app will be exposed publicly using an Ingress resource - resulting in an ALB being launched behind the scenes. HTTP path based routing will be accomplished by leveraging Annotations specified within the Ingress manifest. As a bonus you will also configure an addtional path route (white) which responds with a static message specified directly within the annotation itself.</p>
<p>Choosing an Ingress resource to expose your cluster hosted application to the Internet, will result in the ALBC provisioning an ALB.</p>
<ul>
<li>Create a dedicated namespace to host both versions of the sample web app</li>
</ul>
<pre><code class="language-bash">{
kubectl create ns webapp
kubectl config set-context $(kubectl config current-context) --namespace=webapp
}
</code></pre>
<ul>
<li>Create a ConfigMap for each version of the sample web app. Each ConfigMap will contain a unique message and background colour. Confirm both ConfigMaps were created successfully. In the terminal run the following command: <code>kubectl get cm webapp-cfg-v1 webapp-cfg-v2</code></li>
<li>Create a Deployment for each version of the sample web app. Create both the v1 and v2 deployment resource. </li>
</ul>
<pre><code class="language-yaml">cat &lt;&lt; EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend-v1
  namespace: webapp
  labels:
    role: frontend
    version: v1
spec:
  replicas: 2
  selector:
    matchLabels:
      role: frontend
      version: v1
  template:
    metadata:
      labels:
        role: frontend
        version: v1
    spec:
      containers:
      - name: webapp
        image: cloudacademydevops/webappecho:v3
        imagePullPolicy: IfNotPresent
        command: [&quot;/go/bin/webapp&quot;]
        ports:
        - containerPort: 8080
        env:
        - name: MESSAGE
          valueFrom:
            configMapKeyRef:
              name: webapp-cfg-v1
              key: message
        - name: BACKGROUND_COLOR
          valueFrom:
            configMapKeyRef:
              name: webapp-cfg-v1
              key: bgcolor
EOF
</code></pre>
<ul>
<li>Confirm both Deployments were rolled out successfully. In the terminal run the following command:</li>
</ul>
<pre><code class="language-bash">{
kubectl rollout status deployment frontend-v1
kubectl rollout status deployment frontend-v2
}
</code></pre>
<ul>
<li>Create a Service for each version of the sample web app</li>
</ul>
<pre><code class="language-yaml">apiVersion: v1
kind: Service
metadata:
  name: frontend-v1
  namespace: webapp
  labels:
    role: frontend
    version: v1
spec:
  ports:
  - name: http
    port: 80
    protocol: TCP
    targetPort: 8080
  selector:
    role: frontend
    version: v1
  type: NodePort
EOF
</code></pre>
<ul>
<li>Confirm both Services have been created and respective Pod endpoints (IPs) have been registered successfully. In the terminal run the following command:</li>
</ul>
<pre><code class="language-bash">kubectl get svc,ep
</code></pre>
<ul>
<li>Initially expose just the V1 Service to the Internet. Create an Ingress resource for the V1 sample web app. In the terminal run the following command:</li>
</ul>
<pre><code class="language-yaml">cat &lt;&lt; EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: frontend
  namespace: webapp
  annotations:
    kubernetes.io/ingress.class: alb
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/target-type: ip
spec:
  rules:
    - http:
        paths:
          - pathType: Prefix
            path: /
            backend:
              service:
                name: frontend-v1
                port:
                  number: 80
EOF
</code></pre>
<ul>
<li>Confirm that the Ingress resource was created successfully. In the terminal run the following command:</li>
</ul>
<pre><code class="language-bash">kubectl get ingress frontend
</code></pre>
<ul>
<li>Confirm that the ALB and associated DNS records are created for the Ingress resource. In the terminal run the following command:</li>
</ul>
<pre><code class="language-bash">{
ALB_FQDN=$(kubectl -n webapp get ingress frontend -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
echo ALB_FQDN=$ALB_FQDN
until nslookup $ALB_FQDN &gt;/dev/null 2&gt;&amp;1; do sleep 2 &amp;&amp; echo waiting for DNS to propagate...; done
until curl --silent $ALB_FQDN | grep CloudAcademy &gt;/dev/null 2&gt;&amp;1; do sleep 2 &amp;&amp; echo waiting for ALB to register targets...; done
curl -I $ALB_FQDN
echo
echo READY...
echo browse to:
echo &quot; http://$ALB_FQDN&quot;
}
</code></pre>
<ul>
<li>Update the Ingress resource to include annotations for routing HTTP traffic. Create a new file named <strong>annotations.config</strong> and populate it with <strong>path routing</strong> configuration. In the terminal run the following command:</li>
</ul>
<pre><code class="language-bash">kubernetes.io/ingress.class: alb
alb.ingress.kubernetes.io/scheme: internet-facing
alb.ingress.kubernetes.io/target-type: ip
alb.ingress.kubernetes.io/actions.forward-tg-svc1: &gt;
  {&quot;type&quot;:&quot;forward&quot;,&quot;forwardConfig&quot;:{&quot;targetGroups&quot;:[{&quot;serviceName&quot;:&quot;frontend-v1&quot;,&quot;servicePort&quot;:&quot;80&quot;}]}}
alb.ingress.kubernetes.io/actions.forward-tg-svc2: &gt;
  {&quot;type&quot;:&quot;forward&quot;,&quot;forwardConfig&quot;:{&quot;targetGroups&quot;:[{&quot;serviceName&quot;:&quot;frontend-v2&quot;,&quot;servicePort&quot;:&quot;80&quot;}]}}
alb.ingress.kubernetes.io/actions.custom-path1: &gt;
  {&quot;type&quot;:&quot;fixed-response&quot;,&quot;fixedResponseConfig&quot;:{&quot;contentType&quot;:&quot;text/plain&quot;,&quot;statusCode&quot;:&quot;200&quot;,&quot;messageBody&quot;:&quot;follow the white rabbit...&quot;}}
EOF
</code></pre>
<ul>
<li>Capture the contents of the <code>annotations.config</code> file in a variable named <code>ANNOTATIONS</code>. In the terminal run the following command:</li>
</ul>
<pre><code class="language-bash">{
ANNOTATIONS=&quot;$(cat annotations.config)&quot;
echo &quot;$ANNOTATIONS&quot;
}
</code></pre>
<ul>
<li>Create a new file named ingress.annotations.yaml and populate it with the Ingress manifest configuration, injecting the updated set of path routing annotations. In the terminal run the following command:</li>
</ul>
<pre><code class="language-yaml">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: frontend
  namespace: webapp
  annotations:
$ANNOTATIONS
spec:
  rules:
    - http:
        paths:
          - path: /yellow
            pathType: Exact
            backend:
              service:
                name: forward-tg-svc1
                port:
                  name: use-annotation
          - path: /cyan
            pathType: Exact
            backend:
              service:
                name: forward-tg-svc2
                port:
                  name: use-annotation
          - path: /white
            pathType: Exact
            backend:
              service:
                name: custom-path1
                port:
                  name: use-annotation
EOF
</code></pre>
<ul>
<li>Apply the updated Ingress into the cluster - <code>kubectl apply -f ingress.annotations.yaml</code></li>
</ul>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.a264c092.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.4e0fa4ba.min.js"></script>
      
    
  </body>
</html>